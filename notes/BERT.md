## BERT

> 论文：《BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding》
> 全名：Bidirectional Encoder Representations from Transformers



#### 背景

预训练语言模型

#### 创新点

#### 主要工作